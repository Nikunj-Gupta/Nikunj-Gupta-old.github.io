---
layout: page
permalink: /CV/
title: CV 
rank: 4
description: My official <span style="color:#0080ff;font-size:15px"><a href="https://www.dropbox.com/s/n85oxb7zkh9gc43/CV.pdf?dl=0"> Curriculum Vitae </a> </span> and <span style="color:#0080ff;font-size:15px">research statement</span> and <span style="color:#0080ff;font-size:15px">goals</span>! 
nav: true
---

My main research objectives are inclined towards **multi-agent reinforcement learning**, **human-in-the-loop artificial intelligence**, and **machine perception** to build highly *interactive*, *intelligent*, and most importantly, extremely *adaptable*, autonomous systems. I am interested in exploring and developing **goal-directed methods** that can be used for **sequential decision-making** in real-world scenarios. Additionally, agents must be *safe* and *flexible* to work with and around *humans in the loop*. In the long run, I aim to seek answers to profound mysteries like â€“ How do humans make influential modal judgments and claims based only on their experiences in the actual world? What cognitive algorithms humans use to solve problems like ontological crises? Can we design self-modifying goal-driven autonomous agents that can change their goals and possibly create more powerful agents with different goals? Answers to them could help us enable agents to **learn**, **perceive**, **act**, and **think** in the real world and **maximize human values**. 

Specifically, I do not want to feed upon the wonderful promises of technology lying ahead of us, rather want to think about what AI can do now. **Interaction** plays an important role in human intelligence and I would like to understand how it can be used to achieve goals, make choices, or use available sources of information in software systems. Furthermore, I believe that an individual agent (human or artificial) need not learn each and everything on its own, from scratch. They can do so by **cooperating** with others in the environment, **communication**, or even by **hierarchical learning**. Individually, they can use their own past experiences, and by **multi-agent learning**, we can bring in *scalability*, *computational efficiency*, and *robustness*. Recent works have shown that **deep reinforcement learning** methods have integrated well with **multi-agent systems** with the transpiring field of multi-agent reinforcement learning (MARL). Moreover, recent work in MARL has also shown success in the **emergence of human-relevant skills and strategies** from multi-agent competition and scaled standard reinforcement learning methods. This would mean that AI agents could learn extremely complex and **human-relevant behavior** in the near future which is immensely intriguing to me. Exploring and improving upon current works, I want to develop **novel** and **error-free algorithms** alongside meticulously evaluating them on real-world applications. 

<a href="https://www.dropbox.com/s/n85oxb7zkh9gc43/CV.pdf?dl=0"> Curriculum Vitae </a> 
<a> &emsp; | &emsp; </a> 
<a href="https://www.dropbox.com/home/academic_documents?preview=Resume.pdf"> Resume (1 page)</a> 
<a> &emsp; | &emsp; </a> 
<a href="https://scholar.google.com/citations?user=nargncAAAAAJ&hl=en"> Google Scholar </a> 
<a> &emsp; | &emsp; </a> 
<a href="https://www.linkedin.com/in/nikunj-gupta97/"> LinkedIn </a> 

